
R version 4.5.2 (2025-10-31) -- "[Not] Part in a Rumble"
Copyright (C) 2025 The R Foundation for Statistical Computing
Platform: aarch64-apple-darwin20

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> # This file is part of the testthat infrastructure for the strategize package.
> # It is automatically executed by R CMD check.
> 
> library(testthat)
> library(strategize)
> 
> test_check("strategize")
-------------
strategize() call has begun...
Initializing computational environment...
Initializing outcome models...
[1] 1 1
ok_counter = 0
Done initializing outcome models & starting optimization sequence...
Defining some preliminary objects...
Defining Q functions..
Defining gd function...
Starting optimization...
Optimization type: Gradient ascent
SGD Iteration: 1 of 10
SGD Iteration: 2 of 10
SGD Iteration: 3 of 10
SGD Iteration: 4 of 10
SGD Iteration: 5 of 10
SGD Iteration: 8 of 10
SGD Iteration: 10 of 10
Saving output from gd [getQPiStar_gd]...
SGD Iteration: 1 of 10
SGD Iteration: 2 of 10
SGD Iteration: 3 of 10
SGD Iteration: 4 of 10
SGD Iteration: 5 of 10
SGD Iteration: 8 of 10
SGD Iteration: 10 of 10
Saving output from gd [getQPiStar_gd]...
strategize() call has finished...
-------------
-------------
strategize() call has begun...
Initializing outcome models...
[1] 1 1
ok_counter = 0
Done initializing outcome models & starting optimization sequence...
Defining some preliminary objects...
Defining Q functions..
Defining gd function...
Starting optimization...
Optimization type: Gradient ascent
SGD Iteration: 1 of 20
SGD Iteration: 2 of 20
SGD Iteration: 3 of 20
SGD Iteration: 4 of 20
SGD Iteration: 5 of 20
SGD Iteration: 10 of 20
SGD Iteration: 15 of 20
SGD Iteration: 20 of 20
Saving output from gd [getQPiStar_gd]...
SGD Iteration: 1 of 20
SGD Iteration: 2 of 20
SGD Iteration: 3 of 20
SGD Iteration: 4 of 20
SGD Iteration: 5 of 20
SGD Iteration: 10 of 20
SGD Iteration: 15 of 20
SGD Iteration: 20 of 20
Saving output from gd [getQPiStar_gd]...
strategize() call has finished...
-------------
-------------
strategize() call has begun...
Initializing outcome models...
[1] 1 1
ok_counter = 0
Done initializing outcome models & starting optimization sequence...
Defining some preliminary objects...
Defining Q functions..
Defining gd function...
Starting optimization...
Optimization type: Gradient ascent
SGD Iteration: 1 of 10
SGD Iteration: 2 of 10
SGD Iteration: 3 of 10
SGD Iteration: 4 of 10
SGD Iteration: 5 of 10
SGD Iteration: 8 of 10
SGD Iteration: 10 of 10
Saving output from gd [getQPiStar_gd]...
SGD Iteration: 1 of 10
SGD Iteration: 2 of 10
SGD Iteration: 3 of 10
SGD Iteration: 4 of 10
SGD Iteration: 5 of 10
SGD Iteration: 8 of 10
SGD Iteration: 10 of 10
Saving output from gd [getQPiStar_gd]...
strategize() call has finished...
-------------
-------------
strategize() call has begun...
-------------
strategize() call has begun...
-------------
strategize() call has begun...
Initializing outcome models...
[1] 0 1
ok_counter = 0
Starting a glinternet fit...
[1] 0 2
ok_counter = 0
[1] 1 1
ok_counter = 0
[1] 1 2
ok_counter = 0
Done initializing outcome models & starting optimization sequence...
Defining some preliminary objects...
Defining Q functions..
Defining gd function...
Starting optimization...
Optimization type: Gradient ascent
Creating Hessian functions (D=2 parameters per player)
SGD Iteration: 1 of 3
SGD Iteration: 2 of 3
SGD Iteration: 3 of 3
Saving output from gd [getQPiStar_gd]...
SGD Iteration: 1 of 3
SGD Iteration: 2 of 3
SGD Iteration: 3 of 3
Saving output from gd [getQPiStar_gd]...
strategize() call has finished...
-------------
-------------
strategize() call has begun...
Initializing outcome models...
[1] 0 1
ok_counter = 0
Starting a glinternet fit...
[1] 0 2
ok_counter = 0
[1] 1 1
ok_counter = 0
[1] 1 2
ok_counter = 0
Done initializing outcome models & starting optimization sequence...
Defining some preliminary objects...
Defining Q functions..
Defining gd function...
Starting optimization...
Optimization type: Gradient ascent
Creating Hessian functions (D=2 parameters per player)
SGD Iteration: 1 of 3
SGD Iteration: 2 of 3
SGD Iteration: 3 of 3
Saving output from gd [getQPiStar_gd]...
SGD Iteration: 1 of 3
SGD Iteration: 2 of 3
SGD Iteration: 3 of 3
Saving output from gd [getQPiStar_gd]...
strategize() call has finished...
-------------
[ FAIL 0 | WARN 6 | SKIP 74 | PASS 68 ]

══ Skipped tests (74) ══════════════════════════════════════════════════════════
• On CRAN (73): 'test-adversarial.R:278:3', 'test-adversarial.R:316:3',
  'test-adversarial.R:389:3', 'test-adversarial.R:427:3',
  'test-cv-strategize.R:9:3', 'test-cv-strategize.R:29:3',
  'test-cv-strategize.R:48:3', 'test-cv-strategize.R:70:3',
  'test-edge-cases.R:8:3', 'test-edge-cases.R:54:3', 'test-edge-cases.R:103:3',
  'test-input-validation.R:13:3', 'test-input-validation.R:24:3',
  'test-input-validation.R:35:3', 'test-input-validation.R:47:3',
  'test-input-validation.R:59:3', 'test-input-validation.R:75:3',
  'test-input-validation.R:87:3', 'test-input-validation.R:99:3',
  'test-input-validation.R:115:3', 'test-input-validation.R:128:3',
  'test-input-validation.R:141:3', 'test-input-validation.R:154:3',
  'test-input-validation.R:167:3', 'test-input-validation.R:184:3',
  'test-input-validation.R:210:3', 'test-input-validation.R:227:3',
  'test-input-validation.R:248:3', 'test-input-validation.R:263:3',
  'test-input-validation.R:282:3', 'test-input-validation.R:304:3',
  'test-input-validation.R:320:3', 'test-input-validation.R:332:3',
  'test-input-validation.R:352:3', 'test-input-validation.R:364:3',
  'test-input-validation.R:376:3', 'test-input-validation.R:392:3',
  'test-input-validation.R:406:3', 'test-neural.R:6:3', 'test-onestep.R:13:3',
  'test-onestep.R:40:3', 'test-onestep.R:75:3', 'test-onestep.R:99:3',
  'test-onestep.R:122:3', 'test-onestep.R:152:3', 'test-onestep.R:181:3',
  'test-onestep.R:204:3', 'test-penalty-types.R:8:3',
  'test-penalty-types.R:25:3', 'test-penalty-types.R:42:3',
  'test-primary-pushforward.R:10:3', 'test-primary-pushforward.R:109:3',
  'test-primary-pushforward.R:145:3', 'test-primary-pushforward.R:174:3',
  'test-primary-pushforward.R:207:3', 'test-strategize.R:9:3',
  'test-strategize.R:25:3', 'test-strategize.R:46:3', 'test-strategize.R:63:3',
  'test-strategize.R:79:3', 'test-strategize.R:98:3',
  'test-strategize.R:117:3', 'test-strategize.R:144:3',
  'test-visualization.R:14:3', 'test-visualization.R:44:3',
  'test-visualization.R:70:3', 'test-visualization.R:105:3',
  'test-visualization.R:131:3', 'test-visualization.R:152:3',
  'test-visualization.R:176:3', 'test-visualization.R:209:3',
  'test-visualization.R:225:3', 'test-visualization.R:250:3'
• cv_strategize adversarial mode requires larger datasets (n > 5000) for CV
  splitting (1): 'test-adversarial.R:466:3'

[ FAIL 0 | WARN 6 | SKIP 74 | PASS 68 ]
> 
> proc.time()
   user  system elapsed 
 24.353   3.196  20.448 
