
R version 4.5.2 (2025-10-31) -- "[Not] Part in a Rumble"
Copyright (C) 2025 The R Foundation for Statistical Computing
Platform: aarch64-apple-darwin20

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> # This file is part of the testthat infrastructure for the strategize package.
> # It is automatically executed by R CMD check.
> 
> library(testthat)
> library(strategize)
> 
> test_check("strategize")
-------------
strategize() call has begun...
Initializing computational environment...
Initializing outcome models...
[1] 1 1
ok_counter = 0
GLM OOS fit metrics (single, oos_3fold): AUC=0.4357, LogLoss=0.7035, Acc=0.510, Brier=0.2550
Done initializing outcome models & starting optimization sequence...
Defining some preliminary objects...
Defining Q functions..
Defining gd function...
Starting optimization...
Optimization type: Gradient ascent
SGD Iteration: 1 of 10
SGD Iteration: 2 of 10
SGD Iteration: 3 of 10
SGD Iteration: 4 of 10
SGD Iteration: 5 of 10
SGD Iteration: 8 of 10
SGD Iteration: 10 of 10
Saving output from gd [getQPiStar_gd]...
SGD Iteration: 1 of 10
SGD Iteration: 2 of 10
SGD Iteration: 3 of 10
SGD Iteration: 4 of 10
SGD Iteration: 5 of 10
SGD Iteration: 8 of 10
SGD Iteration: 10 of 10
Saving output from gd [getQPiStar_gd]...
strategize() call has finished...
-------------
-------------
strategize() call has begun...
Initializing outcome models...
[1] 1 1
ok_counter = 0
GLM OOS fit metrics (single, oos_3fold): AUC=0.4357, LogLoss=0.7035, Acc=0.510, Brier=0.2550
Done initializing outcome models & starting optimization sequence...
Defining some preliminary objects...
Defining Q functions..
Defining gd function...
Starting optimization...
Optimization type: Gradient ascent
SGD Iteration: 1 of 20
SGD Iteration: 2 of 20
SGD Iteration: 3 of 20
SGD Iteration: 4 of 20
SGD Iteration: 5 of 20
SGD Iteration: 10 of 20
SGD Iteration: 15 of 20
SGD Iteration: 20 of 20
Saving output from gd [getQPiStar_gd]...
SGD Iteration: 1 of 20
SGD Iteration: 2 of 20
SGD Iteration: 3 of 20
SGD Iteration: 4 of 20
SGD Iteration: 5 of 20
SGD Iteration: 10 of 20
SGD Iteration: 15 of 20
SGD Iteration: 20 of 20
Saving output from gd [getQPiStar_gd]...
strategize() call has finished...
-------------
-------------
strategize() call has begun...
Initializing outcome models...
[1] 1 1
ok_counter = 0
GLM OOS fit metrics (single, oos_3fold): AUC=0.4357, LogLoss=0.7035, Acc=0.510, Brier=0.2550
Done initializing outcome models & starting optimization sequence...
Defining some preliminary objects...
Defining Q functions..
Defining gd function...
Starting optimization...
Optimization type: Gradient ascent
SGD Iteration: 1 of 10
SGD Iteration: 2 of 10
SGD Iteration: 3 of 10
SGD Iteration: 4 of 10
SGD Iteration: 5 of 10
SGD Iteration: 8 of 10
SGD Iteration: 10 of 10
Saving output from gd [getQPiStar_gd]...
SGD Iteration: 1 of 10
SGD Iteration: 2 of 10
SGD Iteration: 3 of 10
SGD Iteration: 4 of 10
SGD Iteration: 5 of 10
SGD Iteration: 8 of 10
SGD Iteration: 10 of 10
Saving output from gd [getQPiStar_gd]...
strategize() call has finished...
-------------
ok_counter = 0
Starting a glinternet fit...
Done with glinternet fit...
ok_counter = 1
GLM OOS fit metrics (pairwise, oos_3fold): AUC=0.9844, LogLoss=0.1364, Acc=0.900, Brier=0.0527
-------------
strategize() call has begun...
-------------
strategize() call has begun...
-------------
strategize() call has begun...
Initializing outcome models...
[1] 0 1
ok_counter = 0
Starting a glinternet fit...
GLM OOS fit metrics (pairwise, oos_3fold): AUC=0.1250, LogLoss=4.9329, Acc=0.800, Brier=0.2722
[1] 0 2
ok_counter = 0
GLM OOS fit metrics (pairwise, oos_3fold): AUC=1.0000, LogLoss=0.0000, Acc=1.000, Brier=0.0000
[1] 1 1
ok_counter = 0
GLM OOS fit metrics (pairwise, oos_3fold): AUC=0.5833, LogLoss=6.3148, Acc=0.500, Brier=0.3125
[1] 1 2
ok_counter = 0
GLM OOS fit metrics (pairwise, oos_3fold): AUC=0.0000, LogLoss=11.9563, Acc=0.250, Brier=0.5625
Done initializing outcome models & starting optimization sequence...
Defining some preliminary objects...
Defining Q functions..
Defining gd function...
Starting optimization...
Optimization type: Gradient ascent
Creating Hessian functions (D=2 parameters per player)
SGD Iteration: 1 of 3
SGD Iteration: 2 of 3
SGD Iteration: 3 of 3
Saving output from gd [getQPiStar_gd]...
SGD Iteration: 1 of 3
SGD Iteration: 2 of 3
SGD Iteration: 3 of 3
Saving output from gd [getQPiStar_gd]...
strategize() call has finished...
-------------
-------------
strategize() call has begun...
Initializing outcome models...
[1] 0 1
ok_counter = 0
Starting a glinternet fit...
GLM OOS fit metrics (pairwise, oos_3fold): AUC=0.1250, LogLoss=4.9329, Acc=0.800, Brier=0.2722
[1] 0 2
ok_counter = 0
GLM OOS fit metrics (pairwise, oos_3fold): AUC=1.0000, LogLoss=0.0000, Acc=1.000, Brier=0.0000
[1] 1 1
ok_counter = 0
GLM OOS fit metrics (pairwise, oos_3fold): AUC=0.5833, LogLoss=6.3148, Acc=0.500, Brier=0.3125
[1] 1 2
ok_counter = 0
GLM OOS fit metrics (pairwise, oos_3fold): AUC=0.0000, LogLoss=11.9563, Acc=0.250, Brier=0.5625
Done initializing outcome models & starting optimization sequence...
Defining some preliminary objects...
Defining Q functions..
Defining gd function...
Starting optimization...
Optimization type: Gradient ascent
Creating Hessian functions (D=2 parameters per player)
SGD Iteration: 1 of 3
SGD Iteration: 2 of 3
SGD Iteration: 3 of 3
Saving output from gd [getQPiStar_gd]...
SGD Iteration: 1 of 3
SGD Iteration: 2 of 3
SGD Iteration: 3 of 3
Saving output from gd [getQPiStar_gd]...
strategize() call has finished...
-------------
-------------
strategize() call has begun...
Initializing outcome models...
[1] 0 1
ok_counter = 0
Starting a glinternet fit...
GLM OOS fit metrics (pairwise, oos_3fold): AUC=0.1250, LogLoss=4.9329, Acc=0.800, Brier=0.2722
[1] 0 2
ok_counter = 0
GLM OOS fit metrics (pairwise, oos_3fold): AUC=1.0000, LogLoss=0.0000, Acc=1.000, Brier=0.0000
[1] 1 1
ok_counter = 0
GLM OOS fit metrics (pairwise, oos_3fold): AUC=0.5833, LogLoss=6.3148, Acc=0.500, Brier=0.3125
[1] 1 2
ok_counter = 0
GLM OOS fit metrics (pairwise, oos_3fold): AUC=0.0000, LogLoss=11.9563, Acc=0.250, Brier=0.5625
Done initializing outcome models & starting optimization sequence...
Defining some preliminary objects...
Defining Q functions..
Defining gd function...
Starting optimization...
Optimization type: Gradient ascent
Creating Hessian functions (D=2 parameters per player)
SGD Iteration: 1 of 3
SGD Iteration: 2 of 3
SGD Iteration: 3 of 3
Saving output from gd [getQPiStar_gd]...
SGD Iteration: 1 of 3
SGD Iteration: 2 of 3
SGD Iteration: 3 of 3
Saving output from gd [getQPiStar_gd]...
strategize() call has finished...
-------------
ok_counter = 0
GLM OOS fit metrics (pairwise, oos_3fold): AUC=0.9948, LogLoss=0.0665, Acc=0.970, Brier=0.0235
ok_counter = 0
GLM OOS fit metrics (pairwise, oos_3fold): AUC=0.9933, LogLoss=0.0784, Acc=0.947, Brier=0.0283
ok_counter = 0
GLM OOS fit metrics (single, oos_3fold): AUC=0.7889, LogLoss=0.5426, Acc=0.743, Brier=0.1831
ok_counter = 0
GLM OOS fit metrics (pairwise, oos_3fold): AUC=0.9912, LogLoss=0.0851, Acc=0.955, Brier=0.0300
ok_counter = 0
GLM OOS fit metrics (single, oos_3fold): AUC=0.7933, LogLoss=0.5488, Acc=0.710, Brier=0.1835
ok_counter = 0
GLM OOS fit metrics (pairwise, oos_3fold): AUC=0.9833, LogLoss=0.1153, Acc=0.905, Brier=0.0422
[ FAIL 0 | WARN 38 | SKIP 107 | PASS 110 ]

══ Skipped tests (107) ═════════════════════════════════════════════════════════
• JAX available; neural fit is slow and not exercised here (1):
  'test-prediction-api.R:147:7'
• On CRAN (105): 'test-adversarial.R:278:3', 'test-adversarial.R:316:3',
  'test-adversarial.R:389:3', 'test-adversarial.R:427:3',
  'test-build-backend.R:2:3', 'test-build-backend.R:36:3',
  'test-build-backend.R:85:3', 'test-choice-token-gradient.R:6:3',
  'test-context-head-interaction.R:6:3',
  'test-context-head-interaction.R:116:3',
  'test-context-head-interaction.R:222:3',
  'test-context-head-interaction.R:332:3', 'test-create-p-list.R:2:3',
  'test-create-p-list.R:21:3', 'test-create-p-list.R:31:3',
  'test-create-p-list.R:38:3', 'test-cv-strategize.R:9:3',
  'test-cv-strategize.R:29:3', 'test-cv-strategize.R:48:3',
  'test-cv-strategize.R:70:3', 'test-edge-cases.R:8:3',
  'test-edge-cases.R:54:3', 'test-edge-cases.R:103:3',
  'test-input-validation.R:13:3', 'test-input-validation.R:24:3',
  'test-input-validation.R:35:3', 'test-input-validation.R:47:3',
  'test-input-validation.R:59:3', 'test-input-validation.R:75:3',
  'test-input-validation.R:87:3', 'test-input-validation.R:99:3',
  'test-input-validation.R:115:3', 'test-input-validation.R:128:3',
  'test-input-validation.R:141:3', 'test-input-validation.R:154:3',
  'test-input-validation.R:167:3', 'test-input-validation.R:184:3',
  'test-input-validation.R:210:3', 'test-input-validation.R:227:3',
  'test-input-validation.R:248:3', 'test-input-validation.R:263:3',
  'test-input-validation.R:282:3', 'test-input-validation.R:304:3',
  'test-input-validation.R:320:3', 'test-input-validation.R:332:3',
  'test-input-validation.R:352:3', 'test-input-validation.R:373:3',
  'test-input-validation.R:388:3', 'test-input-validation.R:406:3',
  'test-input-validation.R:421:3', 'test-input-validation.R:439:3',
  'test-input-validation.R:454:3', 'test-input-validation.R:472:3',
  'test-input-validation.R:499:3', 'test-input-validation.R:511:3',
  'test-input-validation.R:523:3', 'test-input-validation.R:539:3',
  'test-input-validation.R:553:3', 'test-neural.R:39:3', 'test-neural.R:65:3',
  'test-neural.R:465:3', 'test-onestep.R:13:3', 'test-onestep.R:40:3',
  'test-onestep.R:75:3', 'test-onestep.R:99:3', 'test-onestep.R:122:3',
  'test-onestep.R:152:3', 'test-onestep.R:181:3', 'test-onestep.R:204:3',
  'test-penalty-types.R:8:3', 'test-penalty-types.R:25:3',
  'test-penalty-types.R:42:3', 'test-presets.R:2:3', 'test-presets.R:27:3',
  'test-primary-pushforward.R:10:3', 'test-primary-pushforward.R:109:3',
  'test-primary-pushforward.R:145:3', 'test-primary-pushforward.R:174:3',
  'test-primary-pushforward.R:207:3', 'test-s3-methods.R:28:3',
  'test-s3-methods.R:39:3', 'test-s3-methods.R:48:3', 'test-s3-methods.R:58:3',
  'test-s3-methods.R:68:3', 'test-strategize.R:9:3', 'test-strategize.R:25:3',
  'test-strategize.R:46:3', 'test-strategize.R:63:3', 'test-strategize.R:79:3',
  'test-strategize.R:98:3', 'test-strategize.R:117:3',
  'test-strategize.R:144:3', 'test-validate-equilibrium-guards.R:2:3',
  'test-validate-equilibrium-guards.R:9:3',
  'test-validate-equilibrium-guards.R:21:3', 'test-visualization.R:14:3',
  'test-visualization.R:44:3', 'test-visualization.R:70:3',
  'test-visualization.R:105:3', 'test-visualization.R:131:3',
  'test-visualization.R:152:3', 'test-visualization.R:176:3',
  'test-visualization.R:209:3', 'test-visualization.R:225:3',
  'test-visualization.R:250:3'
• cv_strategize adversarial mode requires larger datasets (n > 5000) for CV
  splitting (1): 'test-adversarial.R:466:3'

[ FAIL 0 | WARN 38 | SKIP 107 | PASS 110 ]
> 
> proc.time()
   user  system elapsed 
 39.379   4.971  32.196 
