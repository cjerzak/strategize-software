% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/CS_InputValidation.R
\name{validate_strategize_inputs}
\alias{validate_strategize_inputs}
\title{Validate inputs for strategize()}
\usage{
validate_strategize_inputs(
  Y,
  W,
  X = NULL,
  lambda,
  p_list = NULL,
  K = 1,
  pair_id = NULL,
  profile_order = NULL,
  adversarial = FALSE,
  adversarial_model_strategy = "four",
  partial_pooling = NULL,
  partial_pooling_strength = 50,
  competing_group_variable_respondent = NULL,
  competing_group_variable_candidate = NULL,
  competing_group_competition_variable_candidate = NULL,
  outcome_model_type = "glm",
  penalty_type = "KL",
  neural_mcmc_control = NULL,
  diff = FALSE,
  primary_pushforward = "mc",
  primary_strength = 1,
  primary_n_entrants = 1L,
  primary_n_field = 1L,
  rain_gamma = 0.01,
  rain_eta = 0.001
)
}
\arguments{
\item{Y}{Outcome vector}

\item{W}{Factor matrix}

\item{X}{Optional covariate matrix}

\item{lambda}{Regularization parameter}

\item{p_list}{Baseline probability list}

\item{K}{Number of clusters}

\item{pair_id}{Pair identifier}

\item{profile_order}{Profile order indicator for paired choices}

\item{adversarial}{Adversarial mode flag}

\item{adversarial_model_strategy}{Character string indicating whether to use
"four" models (primary + general for each group) or "two" models (one per group
reused for primary and general) in adversarial mode.}

\item{partial_pooling}{Logical indicating whether to partially pool (shrink) group-specific
outcome model coefficients toward a shared average when using the "two" strategy.}

\item{partial_pooling_strength}{Numeric scalar controlling the amount of shrinkage used for
partial pooling in the two-strategy adversarial case.}

\item{competing_group_variable_respondent}{Respondent group variable}

\item{competing_group_variable_candidate}{Candidate group variable}

\item{competing_group_competition_variable_candidate}{Candidate competition variable}

\item{outcome_model_type}{Outcome model type}

\item{penalty_type}{Penalty type}

\item{neural_mcmc_control}{Optional list overriding neural MCMC defaults. In adversarial
neural mode, set \code{neural_mcmc_control$n_bayesian_models = 2} to fit separate AST/DAG
models (default is 1 for a single differential model). Set
\code{neural_mcmc_control$ModelDims} and \code{neural_mcmc_control$ModelDepth} to override
the Transformer hidden width and depth. Set
\code{neural_mcmc_control$cross_candidate_encoder = "term"} (or \code{TRUE}) to include
the opponent-dependent cross-candidate term in pairwise mode, or set
\code{neural_mcmc_control$cross_candidate_encoder = "full"} to enable a full cross-encoder
that jointly encodes both candidates. Use \code{"none"} (or \code{FALSE}) to disable.
For variational inference (subsample_method = "batch_vi"), set
\code{neural_mcmc_control$optimizer} to \code{"adam"} (numpyro.optim),
\code{"adamw"} (AdamW), \code{"adabelief"} (optax), or \code{"muon"} (optax.contrib). Learning-rate decay is controlled by
\code{neural_mcmc_control$svi_lr_schedule} (default \code{"warmup_cosine"}), with optional
\code{svi_lr_warmup_frac} and \code{svi_lr_end_factor}.}

\item{diff}{Difference mode flag}

\item{primary_pushforward}{Primary-stage push-forward estimator}

\item{primary_strength}{Scalar controlling the decisiveness of primaries}

\item{primary_n_entrants}{Number of entrant candidates sampled per party in multi-candidate primaries}

\item{primary_n_field}{Number of field candidates sampled per party in multi-candidate primaries}

\item{rain_gamma}{Non-negative numeric scalar for the RAIN anchor-growth parameter \eqn{\gamma}.
If not supplied, defaults are auto-scaled downward when \code{nSGD} exceeds 100.}

\item{rain_eta}{Optional numeric scalar step size \eqn{\eta} for RAIN. Defaults to
\code{0.001} and is auto-scaled downward when \code{nSGD} exceeds 100 if not supplied.}
}
\value{
TRUE invisibly if validation passes; stops with error otherwise
}
\description{
Validate inputs for strategize()
}
\keyword{internal}
