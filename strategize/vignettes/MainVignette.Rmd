---
title: "Strategizer Package Tutorial"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Strategizer Package Tutorial}
  %\VignetteEngine{knitr::rmarkdown}
  %\usepackage[UTF-8]{inputenc}
---

# Introduction 

The `strategize` package implements methods for finding optimal stochastic interventions in high-dimensional factorial (including conjoint) experiments. Unlike standard AMCE-based analyses, which marginalize outcomes over the existing experimental distribution (often uniform), these methods identify a counterfactual distribution over factors that best achieves a target (e.g., maximizing a vote-choice outcome). In adversarial contexts, multiple distributions can be learned simultaneously (e.g., two political parties each optimizing candidate features in competition). 

This vignette illustrates core functionality:

- **Section 1** constructs a toy dataset (since we do not assume you have your own data in this example).
- **Section 2** demonstrates a two-step approach to (1) fit an outcome model (like a logistic regression) and (2) optimize a *stochastic intervention* to maximize that model's predicted outcome.
- **Section 3** highlights features like adversarial (max-min) scenarios, cross-validation, and multi-cluster expansions.
- **Section 4** briefly shows an alternative one-step M-estimation procedure.

Throughout, we will use raw `R` code chunks to illustrate typical usage in `R`, including how to specify factor-level probability constraints, run the optimization, and interpret the results.

## Installation

This tutorial assumes you have installed the fastrerandomize package, either from source or via GitHub:

```
# If you haven't installed or set up the package:
# devtools::install_github("cjerzak/strategize-software/strategize")

# (Done once) Optionally build the JAX backend if needed - done once 
# strategize::build_backend(conda_env = "strategize")
``` 

## Constructing Example Data

Most methods in `strategize` require: 

- A matrix (or data frame) `W` of factor levels in a factorial/conjoint design. Each column is a factor; each row is a profile or a respondent-task-profile observation. 
- An outcome `Y`. In forced-choice setups, `Y` could be 1 if a given profile is chosen, 0 otherwise. 
- (Optionally) `X`, which are respondent covariates or other features if you want cluster-specific or multi-group analysis.
- A list `p_list` that captures the original assignment probabilities for each factor (the randomization distribution).


Below, we construct a toy dataset:

```{r}
# A small example: Suppose we have a forced-choice design with 1000
# respondent-profile observations, each profile has 3 factors.

# Create a simple data frame 'my_data_red' that includes:
#  - respondent/candidate group variables for adversarial scenarios
#  - factors that will populate FACTOR_MAT_
#  - an outcome Yobs
n <- 4000
my_data_red <- data.frame(
  # For adversarial grouping:
  R_Partisanship = sample(c("Democrat", "Republican"), n, replace = TRUE),
  Party.affiliation_clean = sample(c("Democrat", "Republican"), n, replace = TRUE),
  Party.competition = sample(c("Same", "Different"), n, replace = TRUE),
  
  # For indexing each respondent and task:
  respondentIndex = c(replicate(2,1:(n/2))),
  task = c(replicate(n,1)),
  profile_order = c(replicate((n/2),1),replicate((n/2),2)), # for every respondent and task, there is a profile order 
  
  # Some factors for the conjoint:
  Sex = sample(c("Male", "Female"), n, replace = TRUE),
  Age = sample(c("36-51","52-67","68-76"), n, replace = TRUE),
  Family = sample(c("Single (divorced)", "Single (never married)",
                    "Married (no child)", "Married (two children)"),
                  n, replace = TRUE)
)

# Suppose Yobs is our outcome (e.g., was this profile chosen?)
Yobs <- c(y_ <- rbinom(n/2, 1, prob = 0.5), 1 - y_)  # purely random for illustration

# Construct 'FACTOR_MAT_' from the factor columns we want to optimize over:
FACTOR_MAT_ <- my_data_red[, c("Sex","Age","Family")]

# (Optional) A cluster variable for variance computations:
cluster_var <- my_data_red$respondentIndex   # or something more meaningful

# Pair or choice-set IDs (if forced-choice):
pair_id <- paste0(my_data_red$respondentIndex, "_", my_data_red$task)

# Original assignment probability list (assume uniform or known):
p_list <- list(
  Sex = c("Female" = 0.5, "Male" = 0.5),
  Age = c("36-51" = 1/3, "52-67" = 1/3, "68-76" = 1/3),
  Family = c("Single (divorced)" = 0.25,
             "Single (never married)" = 0.25,
             "Married (no child)" = 0.25,
             "Married (two children)" = 0.25)
)

# If you want 'slates' of candidate features by party (for multi-stage or adversarial):
SlateList <- list(
  "Democratic" = p_list,
  "Republican" = p_list
)

# Illustrative hyperparameter settings 
X <- rbind(X <- matrix(rnorm(n/2 * 2), n/2, 2), X)  # optional respondent covariates
nSGD_TwoStep <- 200
nMonte_MaxMin <- 5
regularizationType <- "KL"    # penalty type ("KL","L2","LogMaxProb", etc.)
conda_env <- "strategize"
GLOBAL_NFOLDS <- 3
nFolds_glm <- 3
lambda_MaxMin <- 0.1
LAMBDA_SEQ <- c(0.01, lambda_MaxMin)
```

This toy dataset has 3 factors, each with 3 levels, and `Y` is a binary outcome that depends on factor levels as above. The distribution is uniform, so `p_list` has 1/3 for each factor-level. Next, we show how to run a two-step approach that (1) fits an outcome model and (2) searches for the factor-level distribution that maximizes the fitted outcome predictions.

# Basic Two-Step Usage for Average-Case Optimization 

## Using `strategize`
We now pass this fitted model to `strategize`, which will search for the factor-level distribution that maximizes the average predicted outcome. Because we are in a simpler context, we might specify `MaxMin=FALSE` to do the \emph{average case} scenario.  We'll set `lambda` for a mild $L_2$ regularization penalty so that our new distribution does not stray too far from `p_list`:

```{r}
library(strategize)

MaxMinValue <- FALSE 
#if MaxMinValue = FALSE, use 'cv_strategize' for standard cross-validation and single-agent optimization.

res_avecase <- {cv_strategize(
  # Core inputs:
  Y = Yobs,
  W = FACTOR_MAT_,
  X = NULL,
  
  # Regularization or penalty inputs:
  lambda = LAMBDA_SEQ,
  penalty_type = regularizationType,
  use_regularization = TRUE,
  
  # Clustering / grouping:
  varcov_cluster_variable = cluster_var, # in applications, this could be respondent
  competing_group_variable_respondent = NULL,
  competing_group_variable_candidate = NULL,
  competing_group_competition_variable_candidate = NULL,
  
  # IDs and factor specification:
  pair_id = pair_id,
  respondent_id = my_data_red$respondentIndex,
  respondent_task_id = my_data_red$task,
  profile_order = my_data_red$profile_order,
  
  # Probability lists:
  p_list = p_list,
  slate_list = SlateList,
  
  # Optimization controls:
  K = 1L,
  force_gaussian = FALSE,
  nSGD = nSGD_TwoStep,
  nMonte_MaxMin = nMonte_MaxMin,
  compute_se = TRUE,
  
  # If we only want a 'difference' structure on the first iteration, for example:
  diff = TRUE,
  
  # Cross-validation folds (only used if calling cv_strategize):
  folds = GLOBAL_NFOLDS,
  nFolds_glm = nFolds_glm,
  
  # Toggling between single-agent vs. adversarial:
  MaxMin = MaxMinValue,
  
  # Python environment management:
  conda_env = conda_env,
  conda_env_required = TRUE
)}

# Inspect results:
res_avecase$pi_star_point     # The learned factor-level distribution(s)
res_avecase$Q_point_mEst     # The estimated performance or outcome

res_avecase$PiStar_se        # Standard errors (if compute_se=TRUE)
res_avecase$Q_se_mEst        # Standard errors 
```

In this snippet, `strategize` searches for the factor-level distribution maximizing predicted `Y`, subject to an $L_2$ penalty that prevents that distribution from deviating too drastically from `p_list`. The output includes:

- `$PiStar_point`: a list of length $D$ (the number of factors), each containing the new factor-level probabilities.
- `$Q_point_mEst`: the estimated average outcome (vote share) at that new distribution.
- `$PiStar_se`: approximate standard errors for the factor probabilities (Delta method).
- `$Q_se_mEst`: approximate standard error for the average outcome.

**Interpretation.** The factor-level probabilities in `PiStar_point` show how `strategize` suggests *reallocating* factor levels, relative to the original `p_list`, to improve the outcome. For instance, if `Position="Center"` gets upweighted, that means the model suggests that a more centrist stance is beneficial. Because of the $L_2$ penalty, we do not push any factor-level probability to $0$ or $1$ but move them in ways that modestly improve predicted `Y`.

### Plotting the Estimated Factor-Level Probabilities

We can compare `p_list` vs. `res_avg$PiStar_point` to see how the method reweights each factor. A simple barplot can suffice:

```{r}
oldpar <- par(mfrow=c(1,3))
for(d in seq_along(p_list)){
  old_probs <- p_list[[d]]
  new_probs <- res_avecase$PiStar_point[[1]][[d]]  # if single cluster

  barplot( rbind(old_probs, new_probs), beside=TRUE,
           col=c("gray","blue"), ylim=c(0,1),
           main=names(p_list)[d], ylab="Prob.")
  legend("topright", legend=c("Original", "Optimal"), fill=c("gray","blue"), cex=0.8)
}
par(oldpar)
```

In a real analysis, you would interpret which factor levels are up-weighted vs. down-weighted, linking them to your experimental factors (e.g., `Party="Rep"` might be heavily favored if that yields higher predicted support).

# Adversarial (Max-Min) Setup
`strategize` also supports an adversarial scenario in which two (or more) distributions are simultaneously optimized. This is relevant in two-party electoral contexts or any zero-sum environment.  In this case, each side tries to maximize or minimize the other's outcome. 

## Max-Min Example
Suppose we want to model a scenario where `Party="A"` tries to maximize the outcome, while `Party="B"` tries to minimize it.  We can approximate the equilibrium by specifying `MaxMin=TRUE`:

```{r}
MaxMinValue <- TRUE
# if MaxMinValue = TRUE, use 'strategize' for a max-min problem; 

res_adversarial <- {strategize(
  # Core inputs:
  Y = Yobs,
  W = FACTOR_MAT_,
  X = NULL,
  
  # Regularization or penalty inputs:
  lambda = lambda_MaxMin,
  penalty_type = regularizationType,
  use_regularization = TRUE,
  
  # Clustering / grouping:
  varcov_cluster_variable = cluster_var,
  competing_group_variable_respondent = my_data_red$R_Partisanship,
  competing_group_variable_candidate = my_data_red$Party.affiliation_clean,
  competing_group_competition_variable_candidate = my_data_red$Party.competition,
  
  # IDs and factor specification:
  pair_id = pair_id,
  respondent_id = my_data_red$respondentIndex,
  respondent_task_id = my_data_red$task,
  profile_order = my_data_red$profile,
  
  # Probability lists:
  p_list = p_list,
  slate_list = SlateList,
  
  # Optimization controls:
  K = 1L,
  force_gaussian = FALSE,
  nSGD = nSGD_TwoStep,
  nMonte_MaxMin = nMonte_MaxMin,
  compute_se = TRUE,
  
  # If we only want a 'difference' structure on the first iteration, for example:
  diff = TRUE,
  
  # Cross-validation folds (only used if calling cv_strategize):
  folds = GLOBAL_NFOLDS,
  nFolds_glm = nFolds_glm,
  
  # Toggling between single-agent vs. adversarial:
  MaxMin = MaxMinValue,
  
  # Python environment management:
  conda_env = conda_env,
  conda_env_required = TRUE
)}

# Inspect results:
res_adversarial$PiStar_point$k1     # The learned factor-level distribution(s)
res_adversarial$PiStar_point$k2     # The learned factor-level distribution(s)
res_adversarial$Q_point_mEst     # The estimated performance or outcome

res_adversarial$PiStar_se$k1        # Standard errors (if compute_se=TRUE)
res_adversarial$PiStar_se$k2        # Standard errors (if compute_se=TRUE)
res_adversarial$Q_se_mEst        # Standard errors (if compute_se=TRUE)
```

Each side's factor-level probabilities can be inspected.  For instance, `k1` might heavily upweight `Experience="High"` if that strongly helps side A, while `k2` might prefer `Experience="Low"` if that helps side B.  In practice, we might further separate respondents by group (e.g., one group is relevant for A's primary, another group for B's primary, etc.), though that requires more advanced usage with arguments like `competing_group_variable_respondent`.

## Cluster-based Optimiation

TBA 
```{r}
res_clust <- {cv_strategize(
  # Core inputs:
  Y = Yobs,
  W = FACTOR_MAT_,
  X = X,

  # Regularization or penalty inputs:
  lambda = LAMBDA_SEQ,
  penalty_type = regularizationType,
  use_regularization = TRUE,

  # Clustering / grouping:
  varcov_cluster_variable = cluster_var, # in applications, this could be respondent
  competing_group_variable_respondent = NULL,
  competing_group_variable_candidate = NULL,
  competing_group_competition_variable_candidate = NULL,

  # IDs and factor specification:
  pair_id = pair_id,
  respondent_id = my_data_red$respondentIndex,
  respondent_task_id = my_data_red$task,
  profile_order = my_data_red$profile_order,

  # Probability lists:
  p_list = p_list,
  slate_list = SlateList,

  # Optimization controls:
  K = 3L,
  force_gaussian = FALSE,
  nSGD = nSGD_TwoStep,
  nMonte_MaxMin = nMonte_MaxMin,
  compute_se = TRUE,

  # Cross-validation folds (only used if calling cv_strategize):
  folds = GLOBAL_NFOLDS,
  nFolds_glm = nFolds_glm,

  # Toggling between single-agent vs. adversarial:
  MaxMin = FALSE,

  # Python environment management:
  conda_env = conda_env,
  conda_env_required = TRUE
)}

# Inspect results:
res_clust$PiStar_point     # The learned factor-level distribution(s)
res_clust$Q_point_mEst     # The estimated performance or outcome

res_clust$PiStar_se        # Standard errors (if compute_se=TRUE)
res_clust$Q_se_mEst  
```


# Advanced Topics

Additional advanced functionalities include:

- `use_regularization = TRUE` if you want *both* the distribution itself *and* the outcome model to be regularized (especially for many factors).
- `slate_list` to restrict certain factors (like if you have a known set of feasible factor-level combos in a candidate primary).
- Cluster-based expansions for multi-cluster designs, specifying `K > 1` for a mixture approach.

## Conclusion

This vignette has illustrated the core usage of the `strategize` package for:

1. Defining factor-level assignment probabilities (the original design).
2. Fitting an outcome model or passing your own model estimates.
3. Optimizing to find an *average-case* or *adversarial* (max-min) solution for a new factor-level distribution.
4. Interpreting the estimated solution, e.g., the new distribution that up- or down-weights certain levels.

We hope this helps you investigate questions of *optimal* or *adversarial* design in conjoint experiments, bridging policy learning and typical factorial designs. Please see the documentation of `strategize`, `cv_strategize`, and `strategize_onestep` for additional arguments and more advanced use-cases.

<!--
 install.packages( "~/Documents/strategize-software/strategize", repos = NULL, type = "source",force = FALSE)
-->